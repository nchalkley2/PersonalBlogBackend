<!--div class="postcontainer">
	<div class="post">
		<div class="post-text">
			<h1>Networking and Photogrammetry for Dummies</h1>
		
			<hr>

			<h2>Background</h2>
			<p class="fp">
				
				<span class="sntc">I’d say that my job responsibilies as a SIF fellow lie somewhere between creating computer generated art and exploring technological innovation, which is precisely why I love this job so much, as these two activities completely align with my interests.</span> 
				<span class="sntc">For years I have been in love with the 3d art field, and I love keeping up with the front line of technological innovation in art, and the most exciting, new thing on the block in computer generated art is Photogrammetry<sup class="citation" href="#cite_note-4"><a href="#cite_note-4">[1]</a></sup>.</span> 
				<span class="sntc">And the way I see it, photogrammetry is the next big step in computer generated graphics.</span> 
				<span class="sntc">Why I believe that it is the next big step in CG graphics is that it greatly reduces the amount of work artists have to do to create realistic 3d assets, and it gives results that simply can't be beat.</span> 
				<span class="sntc">There's no amount of effort that an artist can put in to an asset to match a scan from real life.</span> 
				<span class="sntc">I’ve been keeping up with photogrammetry’s boundary pushes for a while now; I've been watching presentations about it on GDC’s YouTube page.</span> 
				<span class="sntc">So as I've been keeping up with the boundary pushes photogrammetry has made, I’ve seen independent artists on the website Polycount produce unbelievable work using this technique, and in the past few years, i’ve read about household name companies like Epic Games and Dice using photogrammetry in their work flows to easily make the most realistic graphics possible.</span> 
				<span class="sntc">Needless to say, photogrammetry is an incredibly exciting technological innovation for a 3d artist like me.</span> 
			</p>

			<p class="fp">
				<span class="sntc">Until now, I’ve been talking about photogrammetry at length, and you’re probably wondering how my interest in this art form relates to my work at the SIF program.</span> 
				<span class="sntc">Our latest SIF project, which involves the 3d mapping of Oakland Cemetery, exclusively uses photogrammetry to accomplish its ends.</span> 
			</p>

			<hr>

			<p class="fp">
The Oakland Cemetery project involves using photogrammetry to make a 3d model of the entire cemetery. When I first heard about this project, I was incredibly excited, but then I thought about the sheer amount of work our small team would have to do for the project, and I turned very skeptical. Oakland cemetery covers a whopping 88 acres of land, and we only have a small team working part time to capture the entire cemetery. To say that this task is unfeasible is an understatement. Luckily, we had set up a collaboration with a studio to help us accomplish our project. Which leads me to the second topic covered in this blog post: Networking. We reached out to the studio Beam Imagination for help with our project, and they brought out the big guns.

On the first day of our photoscanning project, they brought a drone to the cemetery to survey the area. By the end of the day, we had already scanned about one-third of the cemetery. So we had our work cut out for us, right? Well, that’s not entirely true. The aerial photoscans provided a good bird's eye view of the cemetery, but it couldn’t capture any fine detail, and the trees covered up most of the cemetery. To get the full scans, we would have to manually do detailed scans with cameras. Luckily Beam Imagination also provided us with very high quality cameras for doing detailed scans. So after the land survey, we decided to sandbox a small area and do A/B testing to determine the best setup for the manual photogrammetry.

We brought out about a hundred thousand dollars worth of equipment to Oakland Cemetery to do the testing. Our lineup of camera bodies included a Sony A7r II, a Nikon D850, and a RED Epic-W. We used an 8mm fisheye lens, an 18mm Zeiss lens, and a 25 mm Zeiss lens with the Sony A7r II, A 14-24mm lens, a 24mm, and a 24-70mm lens with the Nikon, and a 24-70mm lens at 24mm with the RED Epic-W. Agisoft recommends using a 50mm rectilinear (not fisheye) lens to do the scanning, so our lineup choices are a bit oddball. It is even moreso with the RED Epic-W, as Agisoft recommends using still images and the program isn’t designed to work with video. Since we had our equipment lineup for the A/B testing, we just had to do the scanning.
We scanned a statue in our sandbox multiple times with the different camera equipment to do the A/B testing. On the day of the tests, the weather was bright and sunny (Georgia weather sucks for photogrammetry), so we didn’t get the best results. You can notice this in the scans, as the sun is setting pretty rapidly between the different scans.

Once I got all the scanning up, my job was to load the pictures into Agisoft Photoscan and generate a dense point cloud for each set of pictures. The Photoscan program generates quality statistics for each point cloud, so I used those to compare the quality of the scans our different equipment set ups created.

Unfortunately, because of the amount of data we captured, I was not able to compute all of the photogrammetric data for a thorough quality analysis. I was able to get through all of the tests except for the RED Epic-W. I don’t have a computer strong enough to compute the photogrammetric data for every frame, so i’ll have to wait for a few days when I can hog Beam Imagination’s workstation. But according to the data that I did compute, our Test Case 3 had the lowest amount of reprojection error. This test case was composed of 66 images taken with the Sony A7r II and a 18mm lens. Also according to the test data, we had the lowest amount of reprojection error when we corrected for vignetting in the picture, as opposed to no correction and vignette + lens distortion correction. This result matches Dice’s recommendation of only using vignette correction on the photos. 

The next step in our project is a lot less interesting: we have to wait for the weather to get worse. Overcast days are perfect for photogrammetry, and as I mentioned before most Georgia days are sunny. When the sun stops shining, i’ll write an update to this blog post. Until then, have some cool images.

			</p>
			<h2>References/End Notes</h2>
			<div class="reference">
				<ol>
					<li id="cite_note-4">
						<p class="fp"><a href="https://en.wikipedia.org/wiki/Photogrammetry">Photogrammetry</a> is the process of making a 3d model from a set of images.</p>
						<p>Read more: <a href="http://www.theastronauts.com/2014/03/visual-revolution-vanishing-ethan-carter/">Visual Revolution of The Vanishing of Ethan Carter</a></p>
					</li>
				</ol>
			</div>
		
		</div>
	</div>
</div-->